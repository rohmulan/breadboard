export type LLMContent = {
  role?: string;
  parts: DataPart[];
};

export type DataPart = FunctionCallCapabilityPart | TextCapabilityPart;

export type TextCapabilityPart = {
  text: string;
};

export type GeminiSchema = {
  type: "string" | "number" | "integer" | "boolean" | "object" | "array";
  format?: string;
  description?: string;
  nullable?: boolean;
  enum?: string[];
  maxItems?: string;
  minItems?: string;
  properties?: Record<string, GeminiSchema>;
  required?: string[];
  items?: GeminiSchema;
};

export type FunctionCallCapabilityPart = {
  functionCall: {
    name: string;
    args: object;
  };
};

export type FunctionDeclaration = {
  name: string;
  description: string;
  parameters?: GeminiSchema;
};

export type Tool = {
  function_declarations?: FunctionDeclaration[];
};

export type HarmBlockThreshold =
  // Content with NEGLIGIBLE will be allowed.
  | "BLOCK_LOW_AND_ABOVE"
  // Content with NEGLIGIBLE and LOW will be allowed.
  | "BLOCK_MEDIUM_AND_ABOVE"
  // Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
  | "BLOCK_ONLY_HIGH"
  // All content will be allowed.
  | "BLOCK_NONE"
  // Turn off the safety filter.
  | "OFF";

export type HarmCategory =
  // Gemini - Harassment content
  | "HARM_CATEGORY_HARASSMENT"
  //	Gemini - Hate speech and content.
  | "HARM_CATEGORY_HATE_SPEECH"
  // Gemini - Sexually explicit content.
  | "HARM_CATEGORY_SEXUALLY_EXPLICIT"
  // 	Gemini - Dangerous content.
  | "HARM_CATEGORY_DANGEROUS_CONTENT"
  // Gemini - Content that may be used to harm civic integrity.
  | "HARM_CATEGORY_CIVIC_INTEGRITY";

export type SafetySetting = {
  category: HarmCategory;
  threshold: HarmBlockThreshold;
};

export type GeminiBody = {
  contents: LLMContent[];
  tools?: Tool[];
  systemInstruction?: LLMContent;
  safetySettings?: SafetySetting[];
  generationConfig?: GenerationConfig;
};

export type GenerationConfig = {
  responseMimeType?: "text/plain" | "application/json" | "text/x.enum";
  responseSchema?: GeminiSchema;
};

export type FinishReason =
  // Natural stop point of the model or provided stop sequence.
  | "STOP"
  // The maximum number of tokens as specified in the request was reached.
  | "MAX_TOKENS"
  // The response candidate content was flagged for safety reasons.
  | "SAFETY"
  // The response candidate content was flagged for image safety reasons.
  | "IMAGE_SAFETY"
  // The response candidate content was flagged for recitation reasons.
  | "RECITATION"
  // The response candidate content was flagged for using an unsupported language.
  | "LANGUAGE"
  // Unknown reason.
  | "OTHER"
  // Token generation stopped because the content contains forbidden terms.
  | "BLOCKLIST"
  // Token generation stopped for potentially containing prohibited content.
  | "PROHIBITED_CONTENT"
  // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
  | "SPII"
  // The function call generated by the model is invalid.
  | "MALFORMED_FUNCTION_CALL";

export type Candidate = {
  content?: LLMContent;
  finishReason?: FinishReason;
  safetyRatings?: SafetySetting[];
  tokenOutput: number;
  // groundingMetadata: GroundingMetadata;
};

export type GeminiErrorResponse = {
  code?: number;
  message?: string;
  status?: string;
  details?: object[];
};

export type GeminiAPIOutputs = {
  candidates?: Candidate[];
  error?: GeminiErrorResponse;
};

function endpointURL(model?: string) {
  if (!model) {
    model = "gemini-2.0-flash";
  }
  return `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;
}

export async function extractInformation(conversationContext: LLMContent[], informationKey: string, accessToken: string): Promise<string | undefined> {
  const finalContext = [...conversationContext];
  conversationContext.push({
    role: "user",
    parts: [
      {
        text: `Based on our conversation history, has the user provided information for "${informationKey}"? If so, extract it. If not, state "User has not provided the information for ${informationKey} yet."`
      }
    ]
  });
  const requestInit: RequestInit = {
    method: "POST",
    headers: { Authorization: `Bearer ${accessToken}` },
  };
  requestInit.body = JSON.stringify(
    consturctGeminiBodyToExtractInformation(finalContext, informationKey)
  );
  const url = endpointURL("gemini-2.0-flash");
  const data = await fetch(url, requestInit);
  if (!data.ok) {
    return "Error fetching from Geimini API";
  } else {
    const res = (await data.json()) as GeminiAPIOutputs;
    const candidate = res.candidates?.at(0);
    if (!candidate) {
      return "Unable to get a good response from Gemini";
    }
    const content = candidate.content;
    const textData = (content?.parts[0] as TextCapabilityPart).text;
    console.log("Print text data from Gemini %s", textData);
    const cleanedText = textData.replace(/```json\n?|```/g, '').trim();
    const parsedJsonData = JSON.parse(cleanedText);
    if (parsedJsonData.found) {
      return parsedJsonData.value;
    } else {
      return undefined;
    }
  }
}

export async function gemini(
  userInputContext: LLMContent[],
  boardDescription: string,
  accessToken: string,
): Promise<GeminiAPIOutputs> {
  const requestInit: RequestInit = {
    method: "POST",
    headers: { Authorization: `Bearer ${accessToken}` },
  };
  requestInit.body = JSON.stringify(
    consturctGeminiBody(userInputContext, boardDescription)
  );
  const url = endpointURL("gemini-2.0-flash");
  const data = await fetch(url, requestInit);
  if (!data.ok) {
    console.error("Error fetching from Gemini API. Status:", data.status);
    const errorResponse = await data.json();
    const err = errorResponse.error as GeminiErrorResponse;
    console.error("Error details:", errorResponse);
    console.dir(err);
    return { error: err };
  } else {
    // console.log("Complete fetching from gemini API, status:", data.status);
    // Maybe define a response data type GeminiOutput to parse the response?
    const res = (await data.json()) as GeminiAPIOutputs;
    // console.dir(res);
    // console.log("Print candidate to see result...");
    const candidate = res.candidates?.at(0);
    if (!candidate) {
      return { error: {message: "Unable to get a good response from Gemini"}};
    }
    if ("content" in candidate) {
      // console.log("Printing content from the Gemini response");
      // console.dir(candidate.content?.parts[0]);
    }
    return { candidates: res.candidates };
  }
}

function consturctGeminiBody(
  userInputContext: LLMContent[],
  boardDescription: string
): GeminiBody {
  const tools: Tool[] = [
    {
      function_declarations: [
        {
          name: "execute_flow",
          description: `This tool is created by user to execute a specific action. The description is '${boardDescription || ""}'. Read the description and understand it. If user express any intent related the description, execute the tool directly.`,
        },
      ],
    },
  ];
  const systemInstruction: LLMContent = {
    parts: [
      {
        text: buildSystemInstructionText(),
      },
    ],
  };

  const safetySettings: SafetySetting[] = [
    {
      category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HATE_SPEECH",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HARASSMENT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_DANGEROUS_CONTENT",
      threshold: "BLOCK_NONE",
    },
  ];
  const body: GeminiBody = {
    contents: userInputContext,
    tools: tools,
    systemInstruction: systemInstruction,
    safetySettings: safetySettings,
  };
  return body;
}

function consturctGeminiBodyToExtractInformation(
  conversationContext: LLMContent[],
  informationKey: string
): GeminiBody {
  const systemInstruction: LLMContent = {
    parts: [
      {
        text: buildInformationExtractionSystemInstruction(informationKey),
      },
    ],
  };
  const safetySettings: SafetySetting[] = [
    {
      category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HATE_SPEECH",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HARASSMENT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_DANGEROUS_CONTENT",
      threshold: "BLOCK_NONE",
    },
  ];
  const body: GeminiBody = {
    contents: conversationContext,
    systemInstruction: systemInstruction,
    safetySettings: safetySettings,
  };
  return body;
}

function buildSystemInstructionText(): string {
  const now = new Date();
  const timeString = now.toDateString();
  const userInfo = `**User information:**
* The current time where the user is located is ${timeString}.`;
  const commonSense = `**Use your knowledge, creativity and common sense:**
* Never ask for clarification for optional tool parameters. You can simply ignore them if they are not provided.
* For non-critical, but required parameters (like title, description, subject, etc.) you should use your creativity to come up with a good value based on the context, when the user did not provide one.
* You can translate across languages, you can do almost any text processing or manipulation.
* You can answer in any language, if the user asks for it.`;
  const commonPatterns = `**Common patterns:**
1. The user asks for something that is not possible to achieve with the current tools or via your knowledge (eg: "please restart my computer").
* Expected behavior: Let the user immediately know that you cannot perform this action, and offer to perform an alternative solution.
2. The user refers to a date (e.g. "next Tuesday", "Friday", "Christmas", "1st October"), but does not provide the full YYYY-MM-DD date.
* For past events it is always the last occurrence, for future events (eg: time off, create event, new deadline) it is always the next occurrence compared to the current time, that is 2025-02-25 12:37:30 +0100 CET (Week 08, Tuesday).
* Expected behavior: Do not ask back, but use your best guess.`;

  const systemInstruction = `${userInfo}\n${commonSense}\n${commonPatterns}`;
  return systemInstruction;
}

function buildInformationExtractionSystemInstruction(informationKey: string): string {
  const informationExtractionInstruction = `You are an intelligent information extraction system. Your sole task is to analyze the provided conversation history and extract the specific piece of information requested.

The conversation history will be provided as a list of message objects, similar to the 'contents' field in a Gemini API request. Each object has a 'role' (either "user" or "model") and 'parts' (a list of content parts, where each part has a 'text' field).

The specific piece of information you are looking for is: "**${informationKey}**".

Task:
1. **Identify relevant messages:** Only consider messages where the \`role\` is "user". Ignore messages from the "model".
2. **Scan for the information:** Carefully read the \`text\` content of each user message. Pay close attention to statements that define or describe the user's intent or requirements for the requested information.
3. **Extract or state absence:**
    - If you find the information corresponding to "**${informationKey}**" in *any* user message, extract *only* that specific piece of information.
    - If the information for "**${informationKey}**" is *not* found in any user message, you must indicate its absence.

Output Format:
**ALWAYS output valid JSON. DO NOT include markdown code block delimiters (e.g., \`\`\`json or \`\`\`). Your response must start directly with '{' and end with '}'.**

If information is found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": "extracted information",
  "found": true
}
\`\`\`

If information is not found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for ${informationKey} yet."
}
\`\`\`

Examples (these examples simulate the 'contents' field from the generateContent request):

---
Example 1: Information found (for "business_name")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My company is called 'Acme Corporation'."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Thank you for that."
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "What are your services?"
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "business_name",
  "value": "Acme Corporation",
  "found": true
}

---
Example 2: Information not found (for "order_number")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "I need help with my order."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Can you provide your order number?"
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "I forgot it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "order_number",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for order_number yet."
}

---
Example 3: Information found with other text (for "shipping_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "Please ship it to 123 Main Street, Anytown, CA 90210."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Got it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "shipping_address",
  "value": "123 Main Street, Anytown, CA 90210",
  "found": true
}

---
Example 4: No clear key reference, but information is present (for "email_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My email is john.doe@example.com, please use that for communication."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "email_address",
  "value": "john.doe@example.com",
  "found": true
}

---
Example 5: Extracting 'code description' from the provided conversation.

Contents:
\`\`\`json
[
    {
      "role": "user",
      "parts": [
        {
          "text": "I want to write some python code to get current local time in string format",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "What is the time right now",
        },
      ],
    },
    {
      "role": "model",
    "parts": [
        {
          "text": "The current time is Thu May 08 2025.",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "Do you know the exact time, including hours, minutes, and seconds?",
        },
      ],
    }
]
\`\`\`

Output:
{
  "key": "code description",
  "value": "get current local time in string format",
  "found": true
}
`;
    return informationExtractionInstruction;
  }
