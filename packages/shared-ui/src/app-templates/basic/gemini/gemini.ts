export type LLMContent = {
  role?: string;
  parts: DataPart[];
};

export type DataPart = FunctionCallCapabilityPart | TextCapabilityPart;

export type TextCapabilityPart = {
  text: string;
};

export type GeminiSchema = {
  type: "string" | "number" | "integer" | "boolean" | "object" | "array";
  format?: string;
  description?: string;
  nullable?: boolean;
  enum?: string[];
  maxItems?: string;
  minItems?: string;
  properties?: Record<string, GeminiSchema>;
  required?: string[];
  items?: GeminiSchema;
};

export type FunctionCallCapabilityPart = {
  functionCall: {
    name: string;
    args: object;
  };
};

export type EnterpriseSearchPart = {
  query: string;
}

export type FunctionDeclaration = {
  name: string;
  description: string;
  parameters?: GeminiSchema;
};

export type Tool = {
  function_declarations?: FunctionDeclaration[];
};

export type HarmBlockThreshold =
  // Content with NEGLIGIBLE will be allowed.
  | "BLOCK_LOW_AND_ABOVE"
  // Content with NEGLIGIBLE and LOW will be allowed.
  | "BLOCK_MEDIUM_AND_ABOVE"
  // Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
  | "BLOCK_ONLY_HIGH"
  // All content will be allowed.
  | "BLOCK_NONE"
  // Turn off the safety filter.
  | "OFF";

export type HarmCategory =
  // Gemini - Harassment content
  | "HARM_CATEGORY_HARASSMENT"
  //	Gemini - Hate speech and content.
  | "HARM_CATEGORY_HATE_SPEECH"
  // Gemini - Sexually explicit content.
  | "HARM_CATEGORY_SEXUALLY_EXPLICIT"
  // 	Gemini - Dangerous content.
  | "HARM_CATEGORY_DANGEROUS_CONTENT"
  // Gemini - Content that may be used to harm civic integrity.
  | "HARM_CATEGORY_CIVIC_INTEGRITY";

export type SafetySetting = {
  category: HarmCategory;
  threshold: HarmBlockThreshold;
};

export type GeminiBody = {
  contents: LLMContent[];
  tools?: Tool[];
  systemInstruction?: LLMContent;
  safetySettings?: SafetySetting[];
  generationConfig?: GenerationConfig;
};

export type GenerationConfig = {
  responseMimeType?: "text/plain" | "application/json" | "text/x.enum";
  responseSchema?: GeminiSchema;
  temperature?: number;
};

export type FinishReason =
  // Natural stop point of the model or provided stop sequence.
  | "STOP"
  // The maximum number of tokens as specified in the request was reached.
  | "MAX_TOKENS"
  // The response candidate content was flagged for safety reasons.
  | "SAFETY"
  // The response candidate content was flagged for image safety reasons.
  | "IMAGE_SAFETY"
  // The response candidate content was flagged for recitation reasons.
  | "RECITATION"
  // The response candidate content was flagged for using an unsupported language.
  | "LANGUAGE"
  // Unknown reason.
  | "OTHER"
  // Token generation stopped because the content contains forbidden terms.
  | "BLOCKLIST"
  // Token generation stopped for potentially containing prohibited content.
  | "PROHIBITED_CONTENT"
  // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
  | "SPII"
  // The function call generated by the model is invalid.
  | "MALFORMED_FUNCTION_CALL";

export type Candidate = {
  content?: LLMContent;
  finishReason?: FinishReason;
  safetyRatings?: SafetySetting[];
  tokenOutput: number;
  // groundingMetadata: GroundingMetadata;
};

export type GeminiErrorResponse = {
  code?: number;
  message?: string;
  status?: string;
  details?: object[];
};

export type GeminiAPIOutputs = {
  candidates?: Candidate[];
  error?: GeminiErrorResponse;
};

function endpointURL(model?: string) {
  if (!model) {
    model = "gemini-2.0-flash";
  }
  return `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;
}

export async function extractInformation(conversationContext: LLMContent[], informationKey: string, accessToken: string): Promise<string | undefined> {
  const finalContext = [...conversationContext];
  finalContext.push({
    role: "user",
    parts: [
      {
        text: `Based on our conversation history, has the user provided information for "${informationKey}"? If so, extract it. If not, state "User has not provided the information for ${informationKey} yet."`
      }
    ]
  });
  const requestInit: RequestInit = {
    method: "POST",
    headers: { Authorization: `Bearer ${accessToken}` },
  };
  requestInit.body = JSON.stringify(
    consturctGeminiBodyToExtractInformation(finalContext, informationKey)
  );
  const url = endpointURL("gemini-2.0-flash");
  const data = await fetch(url, requestInit);
  if (!data.ok) {
    return undefined;
  } else {
    const res = (await data.json()) as GeminiAPIOutputs;
    const candidate = res.candidates?.at(0);
    if (!candidate) {
      return undefined;
    }
    const content = candidate.content;
    const textData = (content?.parts[0] as TextCapabilityPart).text;
    console.log("Print text data from Gemini %s", textData);
    try {
      const cleanedText = textData.replace(/```json\n?|```/g, '').trim();
      const parsedJsonData = JSON.parse(cleanedText);
      if (parsedJsonData.found) {
        return parsedJsonData.value;
      } else {
        return undefined;
      }
    } catch(error) {
      console.error(error);
      return undefined;
    }
  }
}

export async function gemini(
  userInputContext: LLMContent[],
  boardDescription: string,
  accessToken: string,
): Promise<GeminiAPIOutputs> {
  const requestInit: RequestInit = {
    method: "POST",
    headers: { Authorization: `Bearer ${accessToken}` },
  };
  requestInit.body = JSON.stringify(
    consturctGeminiBody(userInputContext, boardDescription)
  );
  // console.log(requestInit.body);
  const url = endpointURL("gemini-2.0-flash");
  const data = await fetch(url, requestInit);
  if (!data.ok) {
    console.error("Error fetching from Gemini API. Status:", data.status);
    const errorResponse = await data.json();
    const err = errorResponse.error as GeminiErrorResponse;
    console.error("Error details:", errorResponse);
    console.dir(err);
    return { error: err };
  } else {
    // console.log("Complete fetching from gemini API, status:", data.status);
    // Maybe define a response data type GeminiOutput to parse the response?
    const res = (await data.json()) as GeminiAPIOutputs;
    // console.dir(res);
    // console.log("Print candidate to see result...");
    const candidate = res.candidates?.at(0);
    // console.log(candidate);
    if (!candidate) {
      return { error: {message: "Unable to get a good response from Gemini"}};
    }
    if ("content" in candidate) {
      // console.log("Printing content from the Gemini response");
      // console.dir(candidate.content?.parts[0]);
    }
    return { candidates: res.candidates };
  }
}

function consturctGeminiBody(
  userInputContext: LLMContent[],
  boardDescription: string
): GeminiBody {
  const tools: Tool[] = [
    {
      function_declarations: [
        {
          name: "execute_flow",
          description: `This tool is created by user to execute a specific action. The description is '${boardDescription || ""}'. Read the description and understand it. If user express any intent related the description, always execute the tool directly. Never ask the input of the tool.`,
        },
      ],
    },
    {
      function_declarations: [
        {
          name: "enterprise_search",
          parameters: {
            type: "object", 
            properties: {
              "query": {
                type: "string",
                description: `The query to run the enterprise search. Inside query, we need to know which entities user want to search. Entities includes: alendar, meetings, emails, drive, documents, buganizer bugs or issues, yaqs, people information. If the user mentioned any related people, please include into the query.`,
// description: `
//              A search query string. This query should be formulated to explicitly include:
//              1.  Target entities to search within (e.g., calendar, meetings, emails, drive, documents, buganizer bugs or issues, yaqs, people information).
//              2.  Any specific people mentioned as relevant to the search (e.g., 'from John Doe', 'shared by Jane Smith', 'meeting with Marketing team').
//              The query should also incorporate the core subject or keywords from the user's original request.`,
              }
            },
            required: ["query"], 
          },
          description: "This tool that takes a query and returns relevant documents from the user's internal enterprise search engine. The tool has access to user's calendar, meetings, emails, drive, documents, buganizer bugs or issues, yaqs, people information, etc. Use this tool any time the user mentions 'search' or the requested information seems like internal corporate related information, just like how Google Search works but on the company's internal data. Sometimes referred to as Moma Search"
        }
      ],
    }
  ];
  const systemInstruction: LLMContent = {
    parts: [
      {
        text: buildSystemInstructionText(boardDescription),
      },
    ],
  };

  const safetySettings: SafetySetting[] = [
    {
      category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HATE_SPEECH",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HARASSMENT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_DANGEROUS_CONTENT",
      threshold: "BLOCK_NONE",
    },
  ];

  const generationConfig: GenerationConfig = {
    temperature: 0,
  }
  const body: GeminiBody = {
    contents: userInputContext,
    tools: tools,
    systemInstruction: systemInstruction,
    safetySettings: safetySettings,
    generationConfig: generationConfig,
  };
  return body;
}

function consturctGeminiBodyToExtractInformation(
  conversationContext: LLMContent[],
  informationKey: string
): GeminiBody {
  const systemInstruction: LLMContent = {
    parts: [
      {
        text: buildInformationExtractionSystemInstruction(informationKey),
      },
    ],
  };
  const safetySettings: SafetySetting[] = [
    {
      category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HATE_SPEECH",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HARASSMENT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_DANGEROUS_CONTENT",
      threshold: "BLOCK_NONE",
    },
  ];
  const body: GeminiBody = {
    contents: conversationContext,
    systemInstruction: systemInstruction,
    safetySettings: safetySettings,
  };
  return body;
}

function buildSystemInstructionText(boardDescription: string): string {
  const now = new Date();
  const timeString = now.toDateString();
  const mainUsage = `
**Your Identity and Key Capabilities**
You are an advanced AI assistant. When introducing yourself, or when a user asks about your capabilities, it's crucial that you clearly and proactively communicate your core strengths.

Your main capability is: ${boardDescription}. If ${boardDescription} is empty, then you can mention execute designed flow as main capability.

Your second capability is: you can also run enterprise search. 


**Guidance for introduction:**
* Ensure to mention the main capability first and introduce your second capability in another sentence.
* Do not repeate the same introduction.

  `;
  const userInfo = `**User information:**
* The current time where the user is located is ${timeString}.`;
  const commonSense = `**Use your knowledge, creativity and common sense:**
* Read the tool description and understand it. If the user shows any intent related the tool, execute the tool directly. Never ask for clarification for optional tool parameters. You can simply ignore them if they are not provided.
* For non-critical, but required parameters (like title, description, subject, etc.) you should use your creativity to come up with a good value based on the context, when the user did not provide one.
* You can translate across languages, you can do almost any text processing or manipulation.
* You can answer in any language, if the user asks for it.`;
  const commonPatterns = `**Common patterns:**
1. The user asks for something that is not possible to achieve with the current tools or via your knowledge (eg: "please restart my computer").
* Expected behavior: Let the user immediately know that you cannot perform this action, and offer to perform an alternative solution.
2. The user refers to a date (e.g. "next Tuesday", "Friday", "Christmas", "1st October"), but does not provide the full YYYY-MM-DD date.
* For past events it is always the last occurrence, for future events (eg: time off, create event, new deadline) it is always the next occurrence compared to the current time, that is 2025-02-25 12:37:30 +0100 CET (Week 08, Tuesday).
* Expected behavior: Do not ask back, but use your best guess.`;

  const systemInstruction = `${mainUsage}\n${userInfo}\n${commonSense}\n${commonPatterns}`;
  return systemInstruction;
}

function buildInformationExtractionSystemInstruction(informationKey: string): string {
  const informationExtractionInstruction = `You are an intelligent information extraction system. Your sole task is to analyze the provided conversation history and extract the specific piece of information requested.

The conversation history will be provided as a list of message objects, similar to the 'contents' field in a Gemini API request. Each object has a 'role' (either "user" or "model") and 'parts' (a list of content parts, where each part has a 'text' field).

The specific piece of information you are looking for is: "**${informationKey}**".

Task:
1. **Identify relevant messages:** Only consider messages where the \`role\` is "user". Ignore messages from the "model".
2. **Scan for the information (from latest to oldest):** Read the \`text\` content of user messages *starting from the most recent message and going backwards through the history*. Pay close attention to statements that define or describe the user's intent or requirements for the requested information.
3. **Extract the *first* match found from the latest user message, or state absence:**
    - If you find the information corresponding to "**${informationKey}**" in *any* user message, extract *only* that specific piece of information from the *latest occurring* user message that contains it. Do not include any other text or conversational filler.
    - If the information for "**${informationKey}**" is *not* found in any user message, you must indicate its absence.

Output Format:
**ALWAYS output valid JSON. DO NOT include markdown code block delimiters (e.g., \`\`\`json or \`\`\`). Your response must start directly with '{' and end with '}'.**

If information is found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": "extracted information",
  "found": true
}
\`\`\`

If information is not found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for ${informationKey} yet."
}
\`\`\`

Examples (these examples simulate the 'contents' field from the generateContent request):

---
Example 1: Information found (for "business_name")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My company is called 'Acme Corporation'."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Thank you for that."
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "What are your services?"
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "business_name",
  "value": "Acme Corporation",
  "found": true
}

---
Example 2: Information not found (for "order_number")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "I need help with my order."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Can you provide your order number?"
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "I forgot it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "order_number",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for order_number yet."
}

---
Example 3: Information found with other text (for "shipping_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "Please ship it to 123 Main Street, Anytown, CA 90210."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Got it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "shipping_address",
  "value": "123 Main Street, Anytown, CA 90210",
  "found": true
}

---
Example 4: No clear key reference, but information is present (for "email_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My email is john.doe@example.com, please use that for communication."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "email_address",
  "value": "john.doe@example.com",
  "found": true
}

---
Example 5: Extracting 'code description' from the provided conversation.

Contents:
\`\`\`json
[
    {
      "role": "user",
      "parts": [
        {
          "text": "I want to write some python code to get current local time in string format",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "What is the time right now",
        },
      ],
    },
    {
      "role": "model",
    "parts": [
        {
          "text": "The current time is Thu May 08 2025.",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "Do you know the exact time, including hours, minutes, and seconds?",
        },
      ],
    }
]
\`\`\`

Output:
{
  "key": "code description",
  "value": "get current local time in string format",
  "found": true
}

---
**Example 6: Latest match prioritization (for "what image do you want to generate")**

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "Please generate an image of a cat."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Okay, a cat image."
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "Actually, I changed my mind. Generate an image of a dog instead."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "what image do you want to generate",
  "value": "dog",
  "found": true
}
`;
    return informationExtractionInstruction;
  }
