export type LLMContent = {
  role?: string;
  parts: DataPart[];
};

export type DataPart = FunctionCallCapabilityPart | TextCapabilityPart;

export type TextCapabilityPart = {
  text: string;
};

export type GeminiSchema = {
  type: "string" | "number" | "integer" | "boolean" | "object" | "array";
  format?: string;
  description?: string;
  nullable?: boolean;
  enum?: string[];
  maxItems?: string;
  minItems?: string;
  properties?: Record<string, GeminiSchema>;
  required?: string[];
  items?: GeminiSchema;
};

export type FunctionCallCapabilityPart = {
  functionCall: {
    name: string;
    args: object;
  };
};

export type FunctionDeclaration = {
  name: string;
  description: string;
  parameters?: GeminiSchema;
};

export type Tool = {
  function_declarations?: FunctionDeclaration[];
};

export type HarmBlockThreshold =
  // Content with NEGLIGIBLE will be allowed.
  | "BLOCK_LOW_AND_ABOVE"
  // Content with NEGLIGIBLE and LOW will be allowed.
  | "BLOCK_MEDIUM_AND_ABOVE"
  // Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
  | "BLOCK_ONLY_HIGH"
  // All content will be allowed.
  | "BLOCK_NONE"
  // Turn off the safety filter.
  | "OFF";

export type HarmCategory =
  // Gemini - Harassment content
  | "HARM_CATEGORY_HARASSMENT"
  //	Gemini - Hate speech and content.
  | "HARM_CATEGORY_HATE_SPEECH"
  // Gemini - Sexually explicit content.
  | "HARM_CATEGORY_SEXUALLY_EXPLICIT"
  // 	Gemini - Dangerous content.
  | "HARM_CATEGORY_DANGEROUS_CONTENT"
  // Gemini - Content that may be used to harm civic integrity.
  | "HARM_CATEGORY_CIVIC_INTEGRITY";

export type SafetySetting = {
  category: HarmCategory;
  threshold: HarmBlockThreshold;
};

export type GeminiBody = {
  contents: LLMContent[];
  tools?: Tool[];
  systemInstruction?: LLMContent;
  safetySettings?: SafetySetting[];
  generationConfig?: GenerationConfig;
};

export type GenerationConfig = {
  responseMimeType?: "text/plain" | "application/json" | "text/x.enum";
  responseSchema?: GeminiSchema;
};

export type FinishReason =
  // Natural stop point of the model or provided stop sequence.
  | "STOP"
  // The maximum number of tokens as specified in the request was reached.
  | "MAX_TOKENS"
  // The response candidate content was flagged for safety reasons.
  | "SAFETY"
  // The response candidate content was flagged for image safety reasons.
  | "IMAGE_SAFETY"
  // The response candidate content was flagged for recitation reasons.
  | "RECITATION"
  // The response candidate content was flagged for using an unsupported language.
  | "LANGUAGE"
  // Unknown reason.
  | "OTHER"
  // Token generation stopped because the content contains forbidden terms.
  | "BLOCKLIST"
  // Token generation stopped for potentially containing prohibited content.
  | "PROHIBITED_CONTENT"
  // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
  | "SPII"
  // The function call generated by the model is invalid.
  | "MALFORMED_FUNCTION_CALL";

export type Candidate = {
  content?: LLMContent;
  finishReason?: FinishReason;
  safetyRatings?: SafetySetting[];
  tokenOutput: number;
  // groundingMetadata: GroundingMetadata;
};

export type GeminiErrorResponse = {
  code?: number;
  message?: string;
  status?: string;
  details?: object[];
};

export type GeminiAPIOutputs = {
  candidates?: Candidate[];
  error?: GeminiErrorResponse;
};

function endpointURL(model: string) {
  if (!model) {
    model = "gemini-2.0-flash";
  }
  return `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=AIzaSyDdyPzV1XXID29vpefaybtUwTeK5wSXnuY`;
}

export async function gemini(
  userInputContext: LLMContent[],
  boardDescription: string,
  informationKey:string,
): Promise<GeminiAPIOutputs> {
  console.log("Start fetching from gemini API");
  //Manually build userInputContext for testing purpose
  userInputContext = [
    {
      role: "user",
      parts: [
        {
          text: "I want to book a meeting with fengwan.",
        },
      ],
    },
    {
      role: "model",
      parts: [
        {
          text: "Sure, what is the time you want to book",
        },
      ],
    },
    {
      role: "user",
      parts: [
        {
          text: "11:00 AM",
        },
      ],
    },
    {
      role: "model",
      parts: [
        {
          text: "Do you want to meet in person?",
        },
      ],
    },
    {
      role: "user",
      parts: [
        {
          text: "No, we can meet online as well."
        },
      ],
    },
  ];
  const finalContents = [...userInputContext];
  finalContents.push({
    role: "user",
    parts: [
      {
        text: `Based on our conversation history, has the user provided information for "${informationKey}"? If so, extract it. If not, state "User has not provided the information for ${informationKey} yet."`
      }
    ]
  });
  // User Oath token in header to call Gemini instead of api key
  //   headers: {
  //     Authorization: `Bearer ${accessToken}`,
  //   },
  const requestInit: RequestInit = {
    method: "POST",
    // headers: { Authorization: `Bearer ${accessToken}` },
    headers: {},
  };
  requestInit.body = JSON.stringify(
    consturctGeminiBody(finalContents, boardDescription, informationKey)
  );
  const url = endpointURL("gemini-2.0-flash");
  const data = await fetch(url, requestInit);
  if (!data.ok) {
    console.error("Error fetching from Gemini API. Status:", data.status);
    const errorResponse = await data.json();
    const err = errorResponse.error as GeminiErrorResponse;
    console.error("Error details:", errorResponse);
    console.dir(err);
    return { error: err };
  } else {
    console.log("Complete fetching from gemini API, status:", data.status);
    // Maybe define a response data type GeminiOutput to parse the response?
    const res = (await data.json()) as GeminiAPIOutputs;
    console.dir(res);
    console.log("Print candidate to see result...");
    const candidate = res.candidates?.at(0);
    if (!candidate) {
      return {
        error: { message: "Unable to get a good response from Gemini" },
      };
    }
    if ("content" in candidate) {
      console.log("Printing content from the Gemini response");
      console.dir(candidate.content?.parts[0]);
    }
    return { candidates: [candidate] };
  }
}

function consturctGeminiBody(
  userInputContext: LLMContent[],
  boardDescription: string,
  informationKey: string,
): GeminiBody {
  // const tools: Tool[] = [
  //   {
  //     function_declarations: [
  //       {
  //         name: "execute_flow",
  //         description: `Executes a specific flow to perform an action based on user input. ${boardDescription || ""}`,
  //         parameters: {
  //           type: "object",
  //           properties: {
  //             flow_user_input: {
  //               type: "string",
  //               description: "The flow input.",
  //             },
  //           },
  //           required: ["flow_user_input"],
  //         },
  //       },
  //     ],
  //   },
  // ];
  const systemInstruction: LLMContent = {
    parts: [
      {
        text: buildInformationExtractionSystemInstruction(informationKey),
      },
    ],
  };

  const safetySettings: SafetySetting[] = [
    {
      category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HATE_SPEECH",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_HARASSMENT",
      threshold: "BLOCK_NONE",
    },
    {
      category: "HARM_CATEGORY_DANGEROUS_CONTENT",
      threshold: "BLOCK_NONE",
    },
  ];
  const body: GeminiBody = {
    contents: userInputContext,
    systemInstruction: systemInstruction,
    safetySettings: safetySettings,
  };
  return body;
}

function buildSystemInstructionText(): string {
  const now = new Date();
  const timeString = now.toDateString();
  const userInfo = `**User information:**
* The current time where the user is located is ${timeString}.`;
  const commonSense = `**Use your knowledge, creativity and common sense:**
* Never ask for clarification for optional tool parameters. You can simply ignore them if they are not provided.
* For non-critical, but required parameters (like title, description, subject, etc.) you should use your creativity to come up with a good value based on the context, when the user did not provide one.
* You can translate across languages, you can do almost any text processing or manipulation.
* You can answer in any language, if the user asks for it.`;
  //   const commonPatterns = `**Common patterns:**
  // 1. The user asks for something that is not possible to achieve with the current tools or via your knowledge (eg: "please restart my computer").
  // * Expected behavior: Let the user immediately know that you cannot perform this action, and offer to perform an alternative solution.
  // 2. The user refers to a date (e.g. "next Tuesday", "Friday", "Christmas", "1st October"), but does not provide the full YYYY-MM-DD date.
  // * For past events it is always the last occurrence, for future events (eg: time off, create event, new deadline) it is always the next occurrence compared to the current time, that is 2025-02-25 12:37:30 +0100 CET (Week 08, Tuesday).
  // * Expected behavior: Do not ask back, but use your best guess.
  // 3. Generating code snippets, coding and debugging. Since you are an expert in software development, you should answer the user directly when they ask you to provide code, or debug. Do not invoke any tools in this case.
  // * Examples: "write a python code that counts the vowels in 'banana'", "what is the problem with this code? code: ...", "explain this code to me: ...", "debug this code: ...", "fix this code: ...", "write a code that calculates <task>", "how to reverse a string in java?".
  // * Expected behavior: You answer the user directly with the generated code, or the explanation of the code. You make sure that you highlight the pros and cons of the various approaches.`;
  const commonPatterns = `**Common patterns:**
1. The user asks for something that is not possible to achieve with the current tools or via your knowledge (eg: "please restart my computer").
* Expected behavior: Let the user immediately know that you cannot perform this action, and offer to perform an alternative solution.
2. The user refers to a date (e.g. "next Tuesday", "Friday", "Christmas", "1st October"), but does not provide the full YYYY-MM-DD date.
* For past events it is always the last occurrence, for future events (eg: time off, create event, new deadline) it is always the next occurrence compared to the current time, that is 2025-02-25 12:37:30 +0100 CET (Week 08, Tuesday).
* Expected behavior: Do not ask back, but use your best guess.`;

  const systemInstruction = `${userInfo}\n${commonSense}\n${commonPatterns}`;
  return systemInstruction
}

function buildInformationExtractionSystemInstruction(informationKey: string): string {
//   const informationExtractionInstruction = `You are an intelligent information extraction system. Your task is to analyze the preceding conversation history to determine if a specific piece of information has been provided.

// The specific piece of information you are looking for is: "**${informationKey}**".

// Task:
// 1. **Identify relevant messages:** Only consider messages where the \`role\` is "user". Ignore messages from the "model".
// 2. **Scan for the information:** Carefully read the \`text\` content of each user message.
// 3. **Extract or state absence:**
//     - If you find the information corresponding to "**${informationKey}**" in any user message, extract *only* that specific piece of information. Do not include any other text or conversational filler.
//     - If the information for "**${informationKey}**" is *not* found in any user message, respond with the exact phrase: "User has not provided the information for ${informationKey} yet."

// Output Format:
// - If information is found: The extracted information (string).
// - If information is not found: "User has not provided the information for ${informationKey} yet."
// `; // No examples needed here, as the task instruction will be explicit in the final content turn.
const informationExtractionInstruction = `You are an intelligent information extraction system. Your sole task is to analyze the provided conversation history and extract the specific piece of information requested.

The conversation history will be provided as a list of message objects, similar to the 'contents' field in a Gemini API request. Each object has a 'role' (either "user" or "model") and 'parts' (a list of content parts, where each part has a 'text' field).

The specific piece of information you are looking for is: "**${informationKey}**".

Task:
1. **Identify relevant messages:** Only consider messages where the \`role\` is "user". Ignore messages from the "model".
2. **Scan for the information (from latest to oldest):** Read the \`text\` content of user messages *starting from the most recent message and going backwards through the history*. Pay close attention to statements that define or describe the user's intent or requirements for the requested information.
3. **Extract the *first* match found from the latest user message, or state absence:**
    - If you find the information corresponding to "**${informationKey}**" in *any* user message, extract *only* that specific piece of information from the *latest occurring* user message that contains it. Do not include any other text or conversational filler.
    - If the information for "**${informationKey}**" is *not* found in any user message, you must indicate its absence.

Output Format:
**ALWAYS output valid JSON. DO NOT include markdown code block delimiters (e.g., \`\`\`json or \`\`\`). Your response must start directly with '{' and end with '}'.**

If information is found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": "extracted information",
  "found": true
}
\`\`\`

If information is not found:
\`\`\`json
{
  "key": "${informationKey}",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for ${informationKey} yet."
}
\`\`\`

Examples (these examples simulate the 'contents' field from the generateContent request):

---
Example 1: Information found (for "business_name")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My company is called 'Acme Corporation'."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Thank you for that."
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "What are your services?"
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "business_name",
  "value": "Acme Corporation",
  "found": true
}

---
Example 2: Information not found (for "order_number")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "I need help with my order."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Can you provide your order number?"
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "I forgot it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "order_number",
  "value": null,
  "found": false,
  "reason": "User has not provided the information for order_number yet."
}

---
Example 3: Information found with other text (for "shipping_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "Please ship it to 123 Main Street, Anytown, CA 90210."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Got it."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "shipping_address",
  "value": "123 Main Street, Anytown, CA 90210",
  "found": true
}

---
Example 4: No clear key reference, but information is present (for "email_address")

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "My email is john.doe@example.com, please use that for communication."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "email_address",
  "value": "john.doe@example.com",
  "found": true
}

---
Example 5: Extracting 'code description' from the provided conversation.

Contents:
\`\`\`json
[
    {
      "role": "user",
      "parts": [
        {
          "text": "I want to write some python code to get current local time in string format",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "What is the time right now",
        },
      ],
    },
    {
      "role": "model",
    "parts": [
        {
          "text": "The current time is Thu May 08 2025.",
        },
      ],
    },
    {
      "role": "user",
      "parts": [
        {
          "text": "Do you know the exact time, including hours, minutes, and seconds?",
        },
      ],
    }
]
\`\`\`

Output:
{
  "key": "code description",
  "value": "get current local time in string format",
  "found": true
}

---
**Example 6: Latest match prioritization (for "what image do you want to generate")**

Contents:
\`\`\`json
[
  {
    "role": "user",
    "parts": [
      {
        "text": "Please generate an image of a cat."
      }
    ]
  },
  {
    "role": "model",
    "parts": [
      {
        "text": "Okay, a cat image."
      }
    ]
  },
  {
    "role": "user",
    "parts": [
      {
        "text": "Actually, I changed my mind. Generate an image of a dog instead."
      }
    ]
  }
]
\`\`\`

Output:
{
  "key": "what image do you want to generate",
  "value": "dog",
  "found": true
}
`;
  return informationExtractionInstruction;
}
